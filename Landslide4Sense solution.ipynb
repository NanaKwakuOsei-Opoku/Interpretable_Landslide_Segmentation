{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "PhfZV9TeICLD",
   "metadata": {
    "id": "PhfZV9TeICLD"
   },
   "source": [
    "# Installation of required libraries and basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bed01",
   "metadata": {
    "executionInfo": {
     "elapsed": 2825,
     "status": "ok",
     "timestamp": 1655612761495,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "f79bed01"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YP_ND2nzBTbS",
   "metadata": {
    "id": "YP_ND2nzBTbS"
   },
   "source": [
    "# Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9rJ-R_t8BIbv",
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1655612839496,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "9rJ-R_t8BIbv"
   },
   "outputs": [],
   "source": [
    "def load_dataset(image_paths, mask_paths=None):\n",
    "    X = np.zeros((len(image_paths), 128, 128, 6), dtype=np.float32)\n",
    "    Y = None\n",
    "    if mask_paths is not None:\n",
    "        Y = np.zeros((len(image_paths), 128, 128, 1), dtype=np.float32)\n",
    "    \n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        with h5py.File(img_path, 'r') as hdf:\n",
    "            data = np.array(hdf.get('img'), dtype=np.float32)\n",
    "\n",
    "        # Replace NaNs\n",
    "        data[np.isnan(data)] = 1e-6\n",
    "   \n",
    "        mid_rgb       = data[:, :, 1:4].max() / 2.0\n",
    "        mid_slope     = data[:, :, 12].max() / 2.0\n",
    "        mid_elevation = data[:, :, 13].max() / 2.0\n",
    "        \n",
    "        # NDVI calculation\n",
    "        data_red = data[:, :, 3]  # B8 in some indices\n",
    "        data_nir = data[:, :, 7]  # Possibly B8A or B7; adapt if needed\n",
    "        ndvi = np.divide(data_nir - data_red,\n",
    "                         (data_nir + data_red) + 1e-6)  # safeguard division\n",
    " \n",
    "        X[i, :, :, 0] = 1.0 - (data[:, :, 3] / (mid_rgb + 1e-6))   # R\n",
    "        X[i, :, :, 1] = 1.0 - (data[:, :, 2] / (mid_rgb + 1e-6))   # G\n",
    "        X[i, :, :, 2] = 1.0 - (data[:, :, 1] / (mid_rgb + 1e-6))   # B\n",
    "        X[i, :, :, 3] = ndvi\n",
    "        X[i, :, :, 4] = 1.0 - (data[:, :, 12] / (mid_slope + 1e-6))     # Slope\n",
    "        X[i, :, :, 5] = 1.0 - (data[:, :, 13] / (mid_elevation + 1e-6)) # Elevation\n",
    "\n",
    "        # Load mask if provided\n",
    "        if mask_paths is not None:\n",
    "            with h5py.File(mask_paths[i], 'r') as hdf_mask:\n",
    "                mask_data = np.array(hdf_mask.get('mask'), dtype=np.float32)\n",
    "            Y[i, :, :, 0] = mask_data\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kbwi-vu7DGsS",
   "metadata": {
    "id": "Kbwi-vu7DGsS"
   },
   "source": [
    "# Preparing Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d80088",
   "metadata": {
    "executionInfo": {
     "elapsed": 2275,
     "status": "ok",
     "timestamp": 1655613020543,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "25d80088"
   },
   "outputs": [],
   "source": [
    "os.chdir(r'/content/gdrive/MyDrive/DL/landslide4Sense')\n",
    "\n",
    "TRAIN_PATH = sorted(glob.glob(\"data/img/*.h5\"))\n",
    "TRAIN_MASK = sorted(glob.glob(\"data/mask/*.h5\"))\n",
    "\n",
    "# Load entire training set\n",
    "TRAIN_XX, TRAIN_YY = load_dataset(TRAIN_PATH, TRAIN_MASK)\n",
    "\n",
    "print(\"Train data shape:\", TRAIN_XX.shape, TRAIN_YY.shape)\n",
    "print(\"Train stats:\", TRAIN_XX.min(), TRAIN_XX.max(), TRAIN_YY.min(), TRAIN_YY.max())\n",
    "\n",
    "# Train/validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    TRAIN_XX, TRAIN_YY, test_size=0.2, shuffle=True\n",
    ")\n",
    "\n",
    "del TRAIN_XX, TRAIN_YY  # free memory if desired\n",
    "\n",
    "# Quick visualization\n",
    "sample_idx = 1545\n",
    "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(15, 10))\n",
    "ax1.set_title(\"RGB image\")\n",
    "ax2.set_title(\"NDVI\")\n",
    "ax3.set_title(\"Slope\")\n",
    "ax4.set_title(\"Elevation\")\n",
    "ax5.set_title(\"Mask\")\n",
    "\n",
    "ax1.imshow(x_train[sample_idx, :, :, 0:3])\n",
    "ax2.imshow(x_train[sample_idx, :, :, 3])\n",
    "ax3.imshow(x_train[sample_idx, :, :, 4])\n",
    "ax4.imshow(x_train[sample_idx, :, :, 5])\n",
    "ax5.imshow(y_train[sample_idx, :, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RBn3CiIxGCkf",
   "metadata": {
    "id": "RBn3CiIxGCkf"
   },
   "source": [
    "## Building and Compiling the UNET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7o7EdemsExth",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1655613101467,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "7o7EdemsExth",
    "outputId": "802c51f5-e555-41ca-c671-3b2a2b3097f7"
   },
   "outputs": [],
   "source": [
    "from utils import recall_m, precision_m, f1_m  # my custom metrics\n",
    "\n",
    "def unet_model(img_height, img_width, img_channels):\n",
    "    inputs = tf.keras.layers.Input((img_height, img_width, img_channels))\n",
    "\n",
    "    # Contracting path\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(inputs)\n",
    "    c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "    c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(p1)\n",
    "    c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "    c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(p2)\n",
    "    c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "    c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c3)\n",
    "    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(p3)\n",
    "    c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c4)\n",
    "    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(p4)\n",
    "    c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "    c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c5)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), \n",
    "                                         padding='same')(c5)\n",
    "    u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(u6)\n",
    "    c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "    c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c6)\n",
    "\n",
    "    u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), \n",
    "                                         padding='same')(c6)\n",
    "    u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(u7)\n",
    "    c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "    c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c7)\n",
    "\n",
    "    u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), \n",
    "                                         padding='same')(c7)\n",
    "    u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(u8)\n",
    "    c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "    c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c8)\n",
    "\n",
    "    u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), \n",
    "                                         padding='same')(c8)\n",
    "    u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(u9)\n",
    "    c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "    c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', \n",
    "                                kernel_initializer='he_normal', \n",
    "                                padding='same')(c9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', f1_m, precision_m, recall_m]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = unet_model(128, 128, 6)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aJl5WDL5HBLt",
   "metadata": {
    "id": "aJl5WDL5HBLt"
   },
   "source": [
    "## Training with Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nw8-1aIxIWTy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1753,
     "status": "ok",
     "timestamp": 1655615366016,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "Nw8-1aIxIWTy",
    "outputId": "d6f6a9b9-8011-4d99-a06e-ef6ec41b7f96"
   },
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.h5\", \n",
    "    monitor=\"val_f1_m\", \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode=\"max\"\n",
    ")\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1_m',\n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [checkpointer, earlyStopping]\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    batch_size=16,\n",
    "    epochs=100,\n",
    "    verbose=2,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model.save(\"model_save.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vPLjXZOKD7ae",
   "metadata": {
    "id": "vPLjXZOKD7ae"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nYPIxOd4t6lb",
   "metadata": {
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1655615435931,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "nYPIxOd4t6lb"
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print(\"Final validation metrics:\")\n",
    "print(\"Loss:\", loss, \"Accuracy:\", accuracy, \n",
    "      \"F1:\", f1_score, \"Precision:\", precision, \"Recall:\", recall)\n",
    "\n",
    "# Plot training history\n",
    "fig, ((ax11, ax12), (ax13, ax14)) = plt.subplots(2, 2, figsize=(20, 15))\n",
    "ax11.plot(history.history['loss'])\n",
    "ax11.plot(history.history['val_loss'])\n",
    "ax11.set_title('Model loss')\n",
    "ax11.set_ylabel('loss')\n",
    "ax11.set_xlabel('epoch')\n",
    "ax11.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "ax12.plot(history.history['precision_m'])\n",
    "ax12.plot(history.history['val_precision_m'])\n",
    "ax12.set_title('Model precision')\n",
    "ax12.set_ylabel('precision')\n",
    "ax12.set_xlabel('epoch')\n",
    "ax12.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "ax13.plot(history.history['recall_m'])\n",
    "ax13.plot(history.history['val_recall_m'])\n",
    "ax13.set_title('Model recall')\n",
    "ax13.set_ylabel('recall')\n",
    "ax13.set_xlabel('epoch')\n",
    "ax13.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "ax14.plot(history.history['f1_m'])\n",
    "ax14.plot(history.history['val_f1_m'])\n",
    "ax14.set_title('Model F1')\n",
    "ax14.set_ylabel('F1')\n",
    "ax14.set_xlabel('epoch')\n",
    "ax14.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ZZsHxhjD_xs",
   "metadata": {
    "id": "6ZZsHxhjD_xs"
   },
   "source": [
    "## Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qVnDfLS3HFyy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 1437,
     "status": "ok",
     "timestamp": 1655615445519,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "qVnDfLS3HFyy",
    "outputId": "4ac6c7aa-f70a-474c-854c-0b914b9e150e"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "pred_img = model.predict(x_valid)\n",
    "pred_img = (pred_img > threshold).astype(np.uint8)\n",
    "\n",
    "img_idx = 155\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n",
    "ax1.imshow(pred_img[img_idx, :, :, 0])\n",
    "ax1.set_title(\"Prediction\")\n",
    "ax2.imshow(y_valid[img_idx, :, :, 0])\n",
    "ax2.set_title(\"Label\")\n",
    "ax3.imshow(x_valid[img_idx, :, :, 0:3])\n",
    "ax3.set_title(\"RGB Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cmrUIw5LSmYC",
   "metadata": {
    "id": "cmrUIw5LSmYC"
   },
   "source": [
    "## Validating on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DwbcnhT5Sorb",
   "metadata": {
    "executionInfo": {
     "elapsed": 3066,
     "status": "ok",
     "timestamp": 1655615497968,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "DwbcnhT5Sorb"
   },
   "outputs": [],
   "source": [
    "validation_url = \"data/validation/img/*.h5\"\n",
    "img_val_paths = sorted(glob.glob(validation_url))\n",
    "\n",
    "VAL_XX, _ = load_dataset(img_val_paths, mask_paths=None)  # no masks here\n",
    "print(\"Validation images shape:\", VAL_XX.shape)\n",
    "\n",
    "# Predict\n",
    "val_preds = model.predict(VAL_XX)\n",
    "val_preds = (val_preds > threshold).astype(np.uint8)\n",
    "\n",
    "# Quick look\n",
    "img_val_idx = 10\n",
    "fig, (axv1, axv2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "axv1.imshow(val_preds[img_val_idx, :, :, 0])\n",
    "axv1.set_title(\"Predicted Mask\")\n",
    "axv2.imshow(VAL_XX[img_val_idx, :, :, 0:3])\n",
    "axv2.set_title(\"RGB\")\n",
    "plt.show()\n",
    "\n",
    "# OPTIONAL: Save out predicted masks\n",
    "write_directory = \"data/validation/mask\"\n",
    "os.makedirs(write_directory, exist_ok=True)\n",
    "for i, img_path in enumerate(img_val_paths):\n",
    "    # Build output mask name from input name\n",
    "    name = os.path.basename(img_path).replace(\"image\", \"mask\")\n",
    "    with h5py.File(os.path.join(write_directory, name), 'w') as h5f:\n",
    "        pred_mask = val_preds[i, :, :, 0]\n",
    "        h5f.create_dataset('mask', data=pred_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca334076",
   "metadata": {},
   "source": [
    "## Interpretability: Saliency Map & Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kBwAQHlPtzfb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 1765,
     "status": "ok",
     "timestamp": 1655615523820,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "kBwAQHlPtzfb",
    "outputId": "13602de7-304e-4b91-8f68-396b8ec7f4f7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def compute_saliency(model, x, class_idx=None):\n",
    "    x_var = tf.Variable(x, dtype=tf.float32)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x_var)\n",
    "        prediction = model(x_var, training=False)  # shape: (1, H, W, 1)\n",
    "        if class_idx is not None:\n",
    "            # If we wanted a specific pixel or region, we'd index into prediction\n",
    "            # e.g. prediction[0, row, col, 0]\n",
    "            loss = prediction[0, :, :, 0][class_idx]\n",
    "        else:\n",
    "            # Sum over entire predicted mask\n",
    "            loss = tf.reduce_sum(prediction)\n",
    "    # Compute gradient of the loss w.r.t. the input\n",
    "    grads = tape.gradient(loss, x_var)\n",
    "    # Take absolute value across channels, then max\n",
    "    saliency = tf.reduce_max(tf.abs(grads), axis=-1)[0]\n",
    "    return saliency.numpy()\n",
    "\n",
    "def grad_cam_segmentation(model, x, layer_name=None):\n",
    "    if layer_name is None:\n",
    "        layer_name = [l.name for l in model.layers if 'conv2d' in l.name][-1]# Heuristically pick the last conv layer in your model & Inspect your model.summary() for exact layer names. \n",
    "    \n",
    "    # Build a sub-model that returns (feature_maps, predictions)\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[\n",
    "            model.get_layer(layer_name).output,\n",
    "            model.output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        feature_maps, predictions = grad_model(x, training=False)\n",
    "        # We'll define the loss as sum over the predicted mask\n",
    "        loss = tf.reduce_sum(predictions)\n",
    "    \n",
    "    # Grad w.r.t. the feature maps & Global average pooling on the grads\n",
    "    grads = tape.gradient(loss, feature_maps)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Multiply each channel in the feature map by the pooled gradient\n",
    "    feature_maps = feature_maps[0]  # remove batch dimension\n",
    "    heatmap = tf.reduce_sum(tf.multiply(feature_maps, pooled_grads), axis=-1)\n",
    "\n",
    "    # ReLU\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    # Normalize\n",
    "    max_val = np.max(heatmap) if np.max(heatmap) != 0 else 1e-6\n",
    "    heatmap /= max_val\n",
    "    heatmap = heatmap.numpy()\n",
    "\n",
    "    # Resize to match original input\n",
    "    h, w = x.shape[1], x.shape[2]\n",
    "    heatmap = cv2.resize(heatmap, (w, h))\n",
    "    return heatmap\n",
    "\n",
    "# Example usage on one validation image\n",
    "test_img = x_valid[None, 0, ...]  # shape (1, 128, 128, 6)\n",
    "saliency_map = compute_saliency(model, test_img)\n",
    "gradcam_map = grad_cam_segmentation(model, test_img, layer_name=None)\n",
    "\n",
    "fig, (ax_s, ax_g) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax_s.imshow(saliency_map, cmap='viridis')\n",
    "ax_s.set_title(\"Saliency Map\")\n",
    "ax_s.axis('off')\n",
    "\n",
    "ax_g.imshow(gradcam_map, cmap='jet')\n",
    "ax_g.set_title(\"Grad-CAM Heatmap\")\n",
    "ax_g.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G6v56LyGsSgk",
   "metadata": {
    "id": "G6v56LyGsSgk"
   },
   "source": [
    "# Sensitivity Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eFUyGUvSsRqt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1655620063821,
     "user": {
      "displayName": "Tek kshetri",
      "userId": "15227640061576992695"
     },
     "user_tz": -420
    },
    "id": "eFUyGUvSsRqt",
    "outputId": "d555a849-eceb-4768-de9e-f397897db1f4"
   },
   "outputs": [],
   "source": [
    "def channel_sensitivity(model, x, channel_idx, baseline='zero'):\n",
    "    original_pred = model.predict(x)[0, :, :, 0]\n",
    "    \n",
    "    x_mod = x.copy()\n",
    "    if baseline == 'zero':\n",
    "        x_mod[0, :, :, channel_idx] = 0.0\n",
    "    else:\n",
    "        # set channel to mean value\n",
    "        mean_val = np.mean(x_mod[0, :, :, channel_idx])\n",
    "        x_mod[0, :, :, channel_idx] = mean_val\n",
    "\n",
    "    new_pred = model.predict(x_mod)[0, :, :, 0]\n",
    "    diff = np.abs(original_pred - new_pred)\n",
    "    mean_diff = diff.mean()\n",
    "    return mean_diff\n",
    "\n",
    "# Example usage: measure each channel’s importance\n",
    "test_img = x_valid[None, 0, ...]  # pick one image\n",
    "num_channels = test_img.shape[-1]\n",
    "for c in range(num_channels):\n",
    "    sensitivity = channel_sensitivity(model, test_img, c, baseline='zero')\n",
    "    print(f\"Channel {c} sensitivity (zero baseline):\", sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e758e1",
   "metadata": {},
   "source": [
    "## Implementing LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627614f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "\n",
    "def explain_with_lime(model, image, num_samples=1000):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    \n",
    "    # Function to predict using the U-Net model; note that LIME expects a 3D image input\n",
    "    def model_predict(images):\n",
    "        images = np.array(images)\n",
    "        # Assuming images are 128x128 with 6 channels\n",
    "        preds = model.predict(images)\n",
    "        # Return predictions in a suitable format; for segmentation, you might flatten the output or summarize per region.\n",
    "        return preds.reshape((images.shape[0], -1))\n",
    "    \n",
    "    explanation = explainer.explain_instance(\n",
    "        image.astype('double'),\n",
    "        model_predict,\n",
    "        top_labels=1,\n",
    "        hide_color=0,\n",
    "        num_samples=num_samples,\n",
    "        segmentation_fn=lambda x: slic(x, n_segments=50, compactness=10)\n",
    "    )\n",
    "    return explanation\n",
    "\n",
    "# Select a representative validation image (e.g., the same test_img used for saliency/Grad-CAM)\n",
    "lime_explanation = explain_with_lime(model, x_valid[0])\n",
    "\n",
    "# Visualize the explanation (this depends on how you want to overlay the superpixel weights)\n",
    "temp, mask = lime_explanation.get_image_and_mask(\n",
    "    label=lime_explanation.top_labels[0],\n",
    "    positive_only=True,\n",
    "    hide_rest=False,\n",
    "    num_features=10,\n",
    "    min_weight=0.0\n",
    ")\n",
    "\n",
    "plt.imshow(temp)\n",
    "plt.title(\"LIME Explanation\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "landslide4Sense_4.ipynb",
   "provenance": [
    {
     "file_id": "1PuehboZEY8s74Kc-eWto951e3-u09ixk",
     "timestamp": 1655299558650
    },
    {
     "file_id": "176rDKOX5XL0bPLtGT5_fl-t3jcMq1MA6",
     "timestamp": 1655216057673
    },
    {
     "file_id": "1ZMNOc60kapzitIXCOlIxO0BQbSBGP-Qu",
     "timestamp": 1655204390096
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
